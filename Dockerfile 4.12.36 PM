FROM python:3.8-slim

# Set environment variables
ENV NLTK_DATA=/usr/share/nltk_data \
    APP_HOME=/app \
    PYTHONUNBUFFERED=1

WORKDIR $APP_HOME

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create directory for NLTK data
RUN mkdir -p $NLTK_DATA

# Install Python dependencies in optimal order
COPY requirements.txt .

RUN pip install --upgrade pip setuptools wheel \
    && pip install numpy==1.24.4

    
RUN pip install spacy==3.7.4 \
    && python -m spacy download en_core_web_sm

RUN pip install --no-cache-dir -r requirements.txt  \
    && python -m nltk.downloader stopwords wordnet omw-1.4 -d $NLTK_DATA

# Copy application code (after pip install for better caching)
COPY . .

# Create models directory (for volume mounting)
RUN mkdir -p $APP_HOME/models



# Verify critical paths
RUN python -c "import os; \
    assert os.path.exists('$APP_HOME/models'), 'Models directory missing'; \
    from pathlib import Path; \
    print('Current directory contents:', [p.name for p in Path('.').iterdir()])"

RUN python -c "from sklearn.exceptions import NotFittedError; \
    import joblib; \
    tfidf = joblib.load('/app/models/tfidf_vectorizer_stack.pkl'); \
    assert hasattr(tfidf, 'vocabulary_'), 'TF-IDF not fitted'"

EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]